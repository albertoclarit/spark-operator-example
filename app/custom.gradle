abstract class UpdateSparkYaml extends DefaultTask {
    @InputDirectory
    abstract DirectoryProperty getLibsDir()

    @OutputFile
    abstract RegularFileProperty getYamlFile()

    @TaskAction
    def updateYaml() {
        def yamlContent = getYamlFile().get().asFile.text
        
        // Find the start of deps.jars section
        def depsStart = yamlContent.indexOf('  deps:')
        def jarsStart = yamlContent.indexOf('    jars:', depsStart)
        def jarsEnd = yamlContent.indexOf('  driver:', jarsStart)
        
        // Get all jar files from libs directory
        def jarFiles = getLibsDir().get().asFile.listFiles()
            .findAll { it.name.endsWith('.jar') }
            .collect { it.name }
            .sort()
        
        // Create new jars section
        def newJarsSection = '  deps:\n    jars:\n'
        jarFiles.each { jar ->
            newJarsSection += '      - "local:///opt/spark/work-dir/jars/' + jar + '"\n'
        }
        
        // Replace the old section with new one
        def newContent = yamlContent.substring(0, depsStart) + 
                        newJarsSection + 
                        yamlContent.substring(jarsEnd)
        
        getYamlFile().get().asFile.text = newContent
        
        println "Updated spark-application.yaml with ${jarFiles.size()} jars"
    }
}

tasks.register('updateSparkYaml', UpdateSparkYaml) {
    dependsOn copyDependencies
    libsDir = layout.projectDirectory.dir('../libs')
    yamlFile = layout.projectDirectory.file('../spark-application.yaml')
}

abstract class SetVersionTask extends DefaultTask {
    @Input
    @Optional
    abstract Property<String> getDockerRepository()

    @Internal
    abstract DirectoryProperty getProjectDir()

    @InputFile
    Provider<RegularFile> getVersionPropertiesFile() {
        return projectDir.file('version.properties')
    }

    @OutputFile
    Provider<RegularFile> getSparkApplicationFile() {
        return projectDir.file('../spark-application.yaml')
    }

    void updateSparkApplicationImage(String repository, String version) {
        def sparkYamlFile = getSparkApplicationFile().get().asFile
        def lines = sparkYamlFile.readLines()
        
        def newLines = lines.collect { line ->
            if (line.trim().startsWith('image:')) {
                return "  image: \"${repository}:${version}\""
            }
            return line
        }
        
        sparkYamlFile.text = newLines.join('\n') + '\n'
        println "Updated spark-application.yaml image to: ${repository}:${version}"
    }

    @TaskAction
    def updateVersion() {
        def props = new Properties()
        getVersionPropertiesFile().get().asFile.withInputStream { props.load(it) }
        def version = props.getProperty('version.semver')
        
        println "Using version from version.properties: ${version}"

        // Update spark-application.yaml if repository is provided
        def repository = getDockerRepository().orNull
        if (repository) {
            updateSparkApplicationImage(repository, version)
        }
    }
}

tasks.register('setVersion', SetVersionTask) {
    dockerRepository = providers.environmentVariable('DOCKER_REPOSITORY')
    projectDir = layout.projectDirectory
}

abstract class DockerBuildPushTask extends DefaultTask {
    @Input
    abstract Property<String> getDockerRepository()

    @InputDirectory
    abstract DirectoryProperty getProjectDir()

    @InputFile
    Provider<RegularFile> getVersionPropertiesFile() {
        return projectDir.file('version.properties')
    }

    String readVersion() {
        def props = new Properties()
        getVersionPropertiesFile().get().asFile.withInputStream { props.load(it) }
        return props.getProperty('version.semver')
    }

    @TaskAction
    def buildAndPush() {
        def repository = getDockerRepository().get()
        if (!repository) {
            throw new GradleException('DOCKER_REPOSITORY environment variable is required')
        }

        def version = readVersion()
        def imageTag = "${repository}:${version}"

        // Build the Docker image
        def buildCmd = ["docker", "build", "-t", imageTag, "."] as String[]
        def buildProc = new ProcessBuilder(buildCmd)
            .directory(projectDir.get().asFile.parentFile)
            .inheritIO()
            .start()
        
        if (buildProc.waitFor() != 0) {
            throw new GradleException('Docker build failed')
        }
        println "Built Docker image: ${imageTag}"

        // Push the Docker image
        def pushCmd = ["docker", "push", imageTag] as String[]
        def pushProc = new ProcessBuilder(pushCmd)
            .directory(projectDir.get().asFile.parentFile)
            .inheritIO()
            .start()
        
        if (pushProc.waitFor() != 0) {
            throw new GradleException('Docker push failed')
        }
        println "Pushed Docker image: ${imageTag}"
    }
}

tasks.register('dockerBuildPush', DockerBuildPushTask) {
    dependsOn tasks.shadowJar, tasks.copyDependencies
    dockerRepository = providers.environmentVariable('DOCKER_REPOSITORY')
    projectDir = layout.projectDirectory
}



tasks.register('buildAndDeploy') {
    dependsOn 'clean'
    dependsOn 'shadowJar'
    dependsOn 'copyDependencies'
    dependsOn 'updateSparkYaml'
    dependsOn 'incrementBuildMeta'
    dependsOn 'setVersion'
    dependsOn 'dockerBuildPush'
    
    tasks.findByName('shadowJar').mustRunAfter 'clean'
    tasks.findByName('copyDependencies').mustRunAfter 'shadowJar'
    tasks.findByName('updateSparkYaml').mustRunAfter 'copyDependencies'
    tasks.findByName('incrementBuildMeta').mustRunAfter 'updateSparkYaml'
    tasks.findByName('setVersion').mustRunAfter 'incrementBuildMeta'
    tasks.findByName('dockerBuildPush').mustRunAfter 'setVersion'
}
