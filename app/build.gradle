/*
 * This file was generated by the Gradle 'init' task.
 *
 * This generated file contains a sample Java application project to get you started.
 * For more details on building Java & JVM projects, please refer to https://docs.gradle.org/8.13/userguide/building_java_projects.html in the Gradle documentation.
 */

plugins {
    // Apply the application plugin to add support for building a CLI application in Java.
    id 'application'
    // Apply the shadow plugin to generate a fat JAR
    id 'com.github.johnrengelman.shadow' version '8.1.1'
}

version = project.hasProperty('releaseVersion') ? project.releaseVersion : '0.1.0'

repositories {
    // Use Maven Central for resolving dependencies.
    mavenCentral()
}

dependencies {
    // Use JUnit Jupiter for testing.
    testImplementation 'org.junit.jupiter:junit-jupiter:5.9.1'

    testRuntimeOnly 'org.junit.platform:junit-platform-launcher'

    // This dependency is used by the application.
    implementation 'com.google.guava:guava:31.1-jre'

    // Apache Spark dependencies
    compileOnly 'org.apache.spark:spark-core_2.12:3.5.5'
    compileOnly 'org.apache.spark:spark-sql_2.12:3.5.5'

    // Hadoop AWS dependencies
    compileOnly 'org.apache.hadoop:hadoop-aws:3.3.4'
    compileOnly 'org.apache.hadoop:hadoop-common:3.3.4'
    compileOnly 'org.apache.hadoop:hadoop-client:3.3.4'
    compileOnly 'org.apache.hadoop:hadoop-hdfs:3.3.4'
    compileOnly 'org.apache.hadoop:hadoop-mapreduce-client-core:3.3.4'
    compileOnly 'com.amazonaws:aws-java-sdk-bundle:1.12.261'
}

// Apply a specific Java toolchain to ease working on different environments.
java {
    toolchain {
        languageVersion = JavaLanguageVersion.of(17)
    }
}

application {
    // Define the main class for the application.
    mainClass = 'org.example.App'
}

tasks.named('test') {
    // Use JUnit Platform for unit tests.
    useJUnitPlatform()
}

shadowJar {
    archiveBaseName.set('app')
    archiveClassifier.set('all')
    archiveVersion.set(version)
    mergeServiceFiles()
}

configurations {
    hadoopAwsDeps
}

dependencies {
    hadoopAwsDeps 'org.apache.hadoop:hadoop-aws:3.3.4'
    hadoopAwsDeps 'org.apache.hadoop:hadoop-common:3.3.4'
    hadoopAwsDeps 'org.apache.hadoop:hadoop-client:3.3.4'
  //  hadoopAwsDeps 'org.apache.hadoop:hadoop-hdfs:3.3.4'
    hadoopAwsDeps 'org.apache.hadoop:hadoop-mapreduce-client-core:3.3.4'
    hadoopAwsDeps 'com.amazonaws:aws-java-sdk-bundle:1.12.261'
}

task copyDependencies(type: Copy) {
    from configurations.hadoopAwsDeps
    into "${rootProject.projectDir}/libs"
}

abstract class UpdateSparkYaml extends DefaultTask {
    @InputDirectory
    abstract DirectoryProperty getLibsDir()

    @OutputFile
    abstract RegularFileProperty getYamlFile()

    @TaskAction
    def updateYaml() {
        def yamlContent = getYamlFile().get().asFile.text
        
        // Find the start of deps.jars section
        def depsStart = yamlContent.indexOf('  deps:')
        def jarsStart = yamlContent.indexOf('    jars:', depsStart)
        def jarsEnd = yamlContent.indexOf('  driver:', jarsStart)
        
        // Get all jar files from libs directory
        def jarFiles = getLibsDir().get().asFile.listFiles()
            .findAll { it.name.endsWith('.jar') }
            .collect { it.name }
            .sort()
        
        // Create new jars section
        def newJarsSection = '  deps:\n    jars:\n'
        jarFiles.each { jar ->
            newJarsSection += '      - "local:///opt/spark/work-dir/jars/' + jar + '"\n'
        }
        
        // Replace the old section with new one
        def newContent = yamlContent.substring(0, depsStart) + 
                        newJarsSection + 
                        yamlContent.substring(jarsEnd)
        
        getYamlFile().get().asFile.text = newContent
        
        println "Updated spark-application.yaml with ${jarFiles.size()} jars"
    }
}

tasks.register('updateSparkYaml', UpdateSparkYaml) {
    dependsOn copyDependencies
    libsDir = layout.projectDirectory.dir('../libs')
    yamlFile = layout.projectDirectory.file('../spark-application.yaml')
}

task setVersion {
    doLast {
        def newVersion = project.hasProperty('newVersion') ? project.newVersion : '0.1.0'
        def gradlePropsFile = file('gradle.properties')
        def props = new Properties()
        if (gradlePropsFile.exists()) {
            gradlePropsFile.withInputStream { props.load(it) }
        }
        props.setProperty('releaseVersion', newVersion)
        gradlePropsFile.withOutputStream { props.store(it, null) }
        println "Updated version to: ${newVersion}"
    }
}
